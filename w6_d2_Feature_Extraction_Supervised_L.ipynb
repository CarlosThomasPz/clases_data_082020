{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion-se busca un numero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal\n",
    "\n",
    "Se han de tener algunas suposiciones previas:\n",
    "\n",
    "+ Exogeneidad débil (predictores libres de error)\n",
    "+ Linealidad\n",
    "+ Homocedasticidad (Var=cte) y Esperanza nula (**E**=0), la esperanza es la media\n",
    "+ Independencia de los errores\n",
    "+ Falta de colinealidad (independencia lineal)\n",
    "\n",
    "$$y=\\beta_0+\\beta_1x_1+\\beta_2x_2+\\beta_3x_3+\\ldots+\\beta_nx_n+\\epsilon$$\n",
    "\n",
    "El objetivo de la regresion lineal es obtener los $\\beta$:\n",
    "+ Algebraicamente:\n",
    "\n",
    "$$\\vec{\\beta} = (X^{T}X)^{-1}X^{T}y$$\n",
    "\n",
    "+ Minimos cuadrados\n",
    "\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y-\\hat{y})^{2}$$\n",
    "\n",
    "Ejemplo)\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + \\epsilon$\n",
    "\n",
    "Entonces, derivando MSE e igualando a 0:\n",
    "\n",
    "$\\beta_0 = \\frac{\\sum y - \\beta_1\\sum x}{n} = \\bar{y} - \\beta_1\\bar{x}$\n",
    "\n",
    "$\\beta_1=\\frac{\\sum (x-\\hat{x})(y-\\hat{y})}{\\sum (x-\\hat{x})}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline        \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.datasets import make_circles, load_boston\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función de Coste o de Pérdida (J)** = Función a minimizar\n",
    "\n",
    "En el caso de la regresión lineal: \n",
    "$$J=MSE$$\n",
    "\n",
    "\n",
    "La regularización es una medida/penalización de la complejidad del modelo. Se añade un término a J que depende del tipo de regularización:\n",
    "\n",
    "$$J = MSE + \\alpha · T$$\n",
    "\n",
    "\n",
    "+ Lasso (L1, norma 1):\n",
    "\n",
    "$$T=\\frac{1}{n}\\sum_{i}  |\\beta_i|$$\n",
    "\n",
    "Muy útil si se sospecha que hay características irrelevantes. Se favorece $\\beta \\approx 0$\n",
    "\n",
    "+ Ridge (L2):\n",
    "\n",
    "$$T=\\frac{1}{2n}\\sum_{i}  \\beta_{i}^{2}$$\n",
    "\n",
    "Muy útil si se sospecha que existe correlación entre las características, minimiza esa correlación. Funciona mejor si todas son relevantes.\n",
    "\n",
    "+ ElasticNet (L1+L2):\n",
    "\n",
    "$$T=r·L1 + (1-r)·L2$$\n",
    "\n",
    "Se usa cuando hay muchas características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Máquinas de Soporte Vectorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data\\2circles.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/2circles_ac.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/2circ_var.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/2circ_pol.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/kernel_trick.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM\n",
    "\n",
    "![](data/svm.png)\n",
    "\n",
    "Genera un hiperplano (n-1)dimensional para separar los datos. Este primer plano es el llamado clasificador lineal (maximizando la distancia a los puntos).\n",
    "\n",
    "$$\\vec{\\omega}\\vec{x}-b=0$$\n",
    "\n",
    "donde :\n",
    "\n",
    "$\\omega$ es el vector normal al plano\n",
    "$x$ son los datos\n",
    "$b$ es el sesgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "![](data/RF.jpg)\n",
    "\n",
    "Arboles de decisión.\n",
    "\n",
    "+ Pros:\n",
    "\n",
    "Modelos sencillos, se pueden visualizar. No necesitan preprocesar mucho los datos. Computacionalmente eficientes.\n",
    "\n",
    "+ Contras:\n",
    "\n",
    "Muy sensibles a pequeñas variaciones de los datos de entrada. Muy sensible a datos no balanceados. Muy dado al overfitting (poco sesgo, mucha varianza), más cuanto más profundo sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
